"""Research query execution service.

Purpose:
    Execute research queries generated by the preflight query planning system
    using the research API orchestrator to search across multiple databases
    and web sources.
External Dependencies:
    Python standard library modules ``logging``, ``dataclasses``, ``json``.
Fallback Semantics:
    Returns partial results when some queries fail. Logs failures and continues
    with successful queries. Empty results returned when all queries fail.
Timeout Strategy:
    Uses timeout configuration from research API orchestrator. Individual query
    execution respects provider-specific timeouts.
"""

import json
import logging
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Dict, List, Optional

from ...domain.preflight.models import BuiltQuery, QueryPlan
from ...research_apis import ResearchAPIOrchestrator, ResearchResult
from .domain_router import DomainRouter

logger = logging.getLogger(__name__)


@dataclass
class QueryExecutionResult:
    """Container for results of executing a query plan.
    
    Attributes:
        query_results: Mapping of query ID to list of research results
        total_queries: Total number of queries in the plan
        successful_queries: Number of queries that returned results
        failed_queries: Number of queries that failed
        total_results: Total number of research results across all queries
        execution_log: List of execution events for observability
    """
    
    query_results: Dict[str, List[ResearchResult]] = field(default_factory=dict)
    total_queries: int = 0
    successful_queries: int = 0
    failed_queries: int = 0
    total_results: int = 0
    execution_log: List[str] = field(default_factory=list)


class ResearchQueryExecutor:
    """Execute research queries using multiple research APIs.
    
    Coordinates query execution across research databases and web search,
    collecting and organizing results for downstream processing.
    """
    
    def __init__(
        self,
        orchestrator: ResearchAPIOrchestrator,
        config: Optional[Dict[str, Any]] = None
    ):
        """Initialize the research query executor.
        
        Args:
            orchestrator: Research API orchestrator instance
            config: Optional configuration for execution behavior
        
        Returns:
            None
        
        Raises:
            None
        
        Side Effects:
            None
        
        Timeout:
            Not applicable for initialization.
        """
        self.orchestrator = orchestrator
        self.config = config or {}
        self.default_max_results = self.config.get('max_results_per_query', 10)
        self.parallel_execution = self.config.get('parallel_execution', True)
        # Domain-aware routing: choose providers per query based on context
        self.router = DomainRouter()
    
    def execute_query_plan(
        self,
        query_plan: QueryPlan,
        *,
        max_results_per_query: Optional[int] = None,
        sources: Optional[List[str]] = None,
        output_path: Optional[Path] = None
    ) -> QueryExecutionResult:
        """Execute all queries in a query plan.
        
        Args:
            query_plan: Query plan containing queries to execute
            max_results_per_query: Optional override for results per query
            sources: Optional list of research sources to query
            output_path: Optional path to save results JSON
        
        Returns:
            QueryExecutionResult containing all research results
        
        Raises:
            None - errors are logged and partial results returned
        
        Side Effects:
            Makes HTTP requests to research APIs. May write results to disk
            if output_path is provided.
        
        Timeout:
            Total time depends on number of queries and provider timeouts.
        """
        max_results = max_results_per_query or self.default_max_results
        
        result = QueryExecutionResult(
            total_queries=len(query_plan.queries)
        )
        
        logger.info(
            "Executing query plan with %d queries (max_results=%d, sources=%s)",
            len(query_plan.queries),
            max_results,
            sources or 'all'
        )
        
        # Execute queries in priority order
        sorted_queries = sorted(query_plan.queries, key=lambda q: q.priority)
        
        for query in sorted_queries:
            try:
                logger.info("Executing query %s: %s", query.id, query.text)
                result.execution_log.append(
                    f"[START] Query {query.id}: {query.purpose}"
                )
                
                # Check if this query depends on other queries
                if query.depends_on_ids:
                    missing_deps = [
                        dep_id for dep_id in query.depends_on_ids
                        if dep_id not in result.query_results
                    ]
                    if missing_deps:
                        logger.warning(
                            "Query %s has unmet dependencies: %s",
                            query.id,
                            missing_deps
                        )
                        result.execution_log.append(
                            f"[SKIP] Query {query.id}: Missing dependencies {missing_deps}"
                        )
                        result.failed_queries += 1
                        continue
                
                # Execute the query across research sources (domain-aware if sources not provided)
                enabled = self.orchestrator.get_available_sources()
                sources_for_query = sources or self.router.select_sources(query.text, enabled)
                logger.info(
                    "Routing query %s to sources: %s",
                    query.id,
                    ", ".join(sources_for_query) if sources_for_query else "<none>"
                )

                search_results = self.orchestrator.search_all(
                    query=query.text,
                    max_results_per_source=max_results,
                    sources=sources_for_query,
                    parallel=self.parallel_execution
                )
                
                result.query_results[query.id] = search_results
                result.total_results += len(search_results)
                result.successful_queries += 1
                
                logger.info(
                    "Query %s returned %d results",
                    query.id,
                    len(search_results)
                )
                result.execution_log.append(
                    f"[SUCCESS] Query {query.id}: {len(search_results)} results"
                )
                
            except Exception as exc:  # noqa: BLE001 - continue with other queries
                logger.error(
                    "Query %s failed: %s",
                    query.id,
                    exc,
                    exc_info=True
                )
                result.execution_log.append(
                    f"[FAILED] Query {query.id}: {str(exc)}"
                )
                result.failed_queries += 1
        
        logger.info(
            "Query plan execution complete: %d/%d successful, %d total results",
            result.successful_queries,
            result.total_queries,
            result.total_results
        )
        
        # Save results if output path provided
        if output_path:
            try:
                self._save_results(result, output_path)
            except Exception as exc:  # noqa: BLE001 - don't fail on save error
                logger.error("Failed to save results to %s: %s", output_path, exc)
        
        return result
    
    def execute_single_query(
        self,
        query: BuiltQuery,
        *,
        max_results: Optional[int] = None,
        sources: Optional[List[str]] = None
    ) -> List[ResearchResult]:
        """Execute a single research query.
        
        Args:
            query: Query to execute
            max_results: Optional override for maximum results
            sources: Optional list of research sources to query
        
        Returns:
            List of ResearchResult objects
        
        Raises:
            None - errors are logged and empty list returned
        
        Side Effects:
            Makes HTTP requests to research APIs
        
        Timeout:
            Depends on provider timeouts and parallel execution setting
        """
        max_res = max_results or self.default_max_results
        
        try:
            logger.info("Executing query: %s", query.text)
            enabled = self.orchestrator.get_available_sources()
            sources_for_query = sources or self.router.select_sources(query.text, enabled)
            logger.info(
                "Routing single query to sources: %s",
                ", ".join(sources_for_query) if sources_for_query else "<none>"
            )
            results = self.orchestrator.search_all(
                query=query.text,
                max_results_per_source=max_res,
                sources=sources_for_query,
                parallel=self.parallel_execution
            )
            logger.info("Query returned %d results", len(results))
            return results
            
        except Exception as exc:  # noqa: BLE001 - defensive handling
            logger.error("Query execution failed: %s", exc, exc_info=True)
            return []
    
    def _save_results(
        self,
        result: QueryExecutionResult,
        output_path: Path
    ) -> None:
        """Save query execution results to JSON file.
        
        Args:
            result: QueryExecutionResult to save
            output_path: Path to output JSON file
        
        Returns:
            None
        
        Raises:
            IOError: If file cannot be written
        
        Side Effects:
            Writes JSON file to disk
        
        Timeout:
            Not applicable for file I/O
        """
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Convert ResearchResults to dictionaries
        serializable_results = {}
        for query_id, results in result.query_results.items():
            serializable_results[query_id] = [
                {
                    'id': r.id,
                    'title': r.title,
                    'authors': r.authors,
                    'abstract': r.abstract,
                    'url': r.url,
                    'published_date': r.published_date,
                    'source': r.source,
                    'metadata': r.metadata,
                    'relevance_score': r.relevance_score,
                }
                for r in results
            ]
        
        output_data = {
            'query_results': serializable_results,
            'summary': {
                'total_queries': result.total_queries,
                'successful_queries': result.successful_queries,
                'failed_queries': result.failed_queries,
                'total_results': result.total_results,
            },
            'execution_log': result.execution_log,
        }
        
        with output_path.open('w', encoding='utf-8') as f:
            json.dump(output_data, f, indent=2, ensure_ascii=False)
        
        logger.info("Saved query execution results to %s", output_path)
